"use strict";(self.webpackChunkplugnmeet_documentation=self.webpackChunkplugnmeet_documentation||[]).push([[1336],{638:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>t,toc:()=>c});var t=i(3502),s=i(5656),r=i(7365);const o={title:"How to Add an AI Meeting Assistant to Your Video App in 15 Minutes",slug:"how-to-add-ai-meeting-assistant-features",authors:["jibon"],tags:["tutorial","how-to","ai-meeting-assistant","ai-meeting-notes","meeting-summary-ai","ai-meeting-summarizer","meeting-assistant-ai","developer"]},a=void 0,l={authorsImageUrls:[void 0]},c=[{value:"The Goal",id:"the-goal",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Step 1: Configure the AI Providers",id:"step-1-configure-the-ai-providers",level:3},{value:"Step 2: Enable AI Features in Your Room",id:"step-2-enable-ai-features-in-your-room",level:3},{value:"Step 3: Experience It Live",id:"step-3-experience-it-live",level:3},{value:"Conclusion",id:"conclusion",level:2}];function d(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(n.p,{children:["In today's competitive landscape, a basic video call is no longer enough. Users expect intelligent, accessible, and productive experiences. What if you could offer an ",(0,s.jsx)(n.strong,{children:"AI meeting assistant"})," that provides live translation and automatically generates ",(0,s.jsx)(n.strong,{children:"AI meeting notes"})," after every session?"]}),"\n",(0,s.jsx)(n.p,{children:"With Plug-N-Meet, you can. This isn't a complex, multi-month integration project. It's a 15-minute configuration change."}),"\n",(0,s.jsxs)(n.p,{children:["This guide will show you how to add world-class ",(0,s.jsx)(n.strong,{children:"AI meeting assistant features"}),"\u2014powered by ",(0,s.jsx)(n.strong,{children:"Microsoft Azure"})," for translation and ",(0,s.jsx)(n.strong,{children:"Google Gemini"})," for your ",(0,s.jsx)(n.strong,{children:"meeting summary AI"}),"\u2014to your Plug-N-Meet integration."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"the-goal",children:"The Goal"}),"\n",(0,s.jsxs)(n.p,{children:["By the end of this guide, your ",(0,s.jsx)(n.strong,{children:"meeting assistant AI"})," will be able to:"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Provide live, real-time captions of the conversation."}),"\n",(0,s.jsx)(n.li,{children:"Translate those captions into any user's preferred language with a single click."}),"\n",(0,s.jsxs)(n.li,{children:["Generate a full ",(0,s.jsx)(n.strong,{children:"meeting summary AI"})," with key decisions and action items after the session ends."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["A running Plug-N-Meet server. If you don't have one, follow our ",(0,s.jsx)(n.a,{href:"/docs/installation",children:"Installation Guide"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["API keys from your chosen AI providers:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"For Live Translation:"})," An API Key and Region from ",(0,s.jsx)(n.a,{href:"https://azure.microsoft.com/en-us/products/ai-services/speech-to-text",children:"Microsoft Azure's Cognitive Services"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"For AI Summaries:"})," An API Key from ",(0,s.jsx)(n.a,{href:"https://aistudio.google.com/app/apikey",children:"Google AI Studio"})," for the Gemini API."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"step-1-configure-the-ai-providers",children:"Step 1: Configure the AI Providers"}),"\n",(0,s.jsxs)(n.p,{children:["The first step is to tell your Plug-N-Meet server how to connect to the AI services. Open your ",(0,s.jsx)(n.code,{children:"config.yaml"})," file on your server and find the ",(0,s.jsx)(n.code,{children:"insights"})," section."]}),"\n",(0,s.jsxs)(n.p,{children:["The new configuration is highly flexible. First, you define your ",(0,s.jsx)(n.code,{children:"providers"})," (your accounts), and then you assign those providers to specific ",(0,s.jsx)(n.code,{children:"services"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["Here is a minimal configuration to enable live transcription and the ",(0,s.jsx)(n.strong,{children:"AI meeting summarizer"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'insights:\n  enabled: true\n  # 1. Define all available provider accounts ONCE.\n  providers:\n    azure:\n      - id: "my-azure-account" # A unique name you choose\n        credentials:\n          api_key: "YOUR_AZURE_KEY"\n          region: "eastus"\n    google:\n      - id: "my-gemini-account" # A unique name you choose\n        credentials:\n          api_key: "YOUR_GEMINI_API_KEY"\n\n  # 2. Define the services that USE the providers.\n  services:\n    # Transcription is required for both live captions and translation.\n    transcription:\n      provider: "azure"\n      id: "my-azure-account"\n\n    # The meeting summarizer will use the audio from the transcription service.\n    meeting_summarizing:\n      provider: "google"\n      id: "my-gemini-account"\n      options:\n        # Use gemini-1.5-flash for faster, cost-effective summaries.\n        # Use gemini-1.5-pro for the highest quality.\n        summarize_model: "gemini-1.5-flash"\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Save the file and ",(0,s.jsx)(n.strong,{children:"restart your PlugNmeet server"})," for the changes to take effect."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"sudo systemctl restart plugnmeet\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"step-2-enable-ai-features-in-your-room",children:"Step 2: Enable AI Features in Your Room"}),"\n",(0,s.jsxs)(n.p,{children:["Now that the server is configured, you can enable these features on a per-room basis. This gives you granular control, allowing you to offer ",(0,s.jsx)(n.strong,{children:"AI meeting assistant features"})," as a premium add-on or only for specific meeting types."]}),"\n",(0,s.jsxs)(n.p,{children:["When you make your ",(0,s.jsx)(n.code,{children:"createRoom"})," API call, add the ",(0,s.jsx)(n.code,{children:"insights_features"})," block to the ",(0,s.jsx)(n.code,{children:"room_features"})," section of your metadata."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{\n  "room_id": "ai-powered-room",\n  "metadata": {\n    "room_features": {\n      // ... other features like allow_webcams, etc.\n      "insights_features": {\n        "is_allow": true,\n        "transcription_features": {\n          "is_allow": true,\n          "is_allow_translation": true\n        },\n        "ai_features": {\n          "is_allow": true,\n          "meeting_summarization_features": {\n            "is_allow": true\n          }\n        }\n      }\n    }\n  }\n}\n'})}),"\n",(0,s.jsx)(n.p,{children:"That's it! Any room created with this metadata will now have the AI Meeting Assistant enabled."}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"step-3-experience-it-live",children:"Step 3: Experience It Live"}),"\n",(0,s.jsx)(n.p,{children:"When a user joins a room created with these settings, the AI features are available to be activated by a moderator."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Live Captions & Translation:"})," A moderator must first enable the service."]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Click the ",(0,s.jsx)(n.strong,{children:"3-dots menu"})," in the control bar."]}),"\n",(0,s.jsxs)(n.li,{children:["Select ",(0,s.jsx)(n.strong,{children:"Transcription and Translation"}),"."]}),"\n",(0,s.jsx)(n.li,{children:"In the pop-up, select the primary speaker and the language they will be speaking."}),"\n",(0,s.jsxs)(n.li,{children:["Click ",(0,s.jsx)(n.strong,{children:"Start Service"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Once enabled, participants will see a new ",(0,s.jsx)(n.strong,{children:'"T" icon'}),' in their main control bar (next to icons like Raise Hand, Whiteboard, etc.). Clicking this "T" icon opens a menu where they can view the live captions and select their own preferred language for translation.']}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Automated Meeting Notes:"})," To generate ",(0,s.jsx)(n.strong,{children:"AI meeting notes"}),", a moderator must start the summarization service."]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Click the ",(0,s.jsx)(n.strong,{children:"3-dots menu"})," in the control bar."]}),"\n",(0,s.jsxs)(n.li,{children:["Select ",(0,s.jsx)(n.strong,{children:"AI Tools"}),", then ",(0,s.jsx)(n.strong,{children:"Meeting Summarization"}),"."]}),"\n",(0,s.jsx)(n.li,{children:'(Optional) Add custom instructions in the "Summarization Instructions" text area to guide the AI.'}),"\n",(0,s.jsxs)(n.li,{children:["Click ",(0,s.jsx)(n.strong,{children:"Start Service"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.strong,{children:"meeting assistant AI"})," will then process the audio in the background. After the meeting, the summary will be generated."]}),"\n",(0,s.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,s.jsxs)(n.p,{children:["In just a few minutes, you've transformed a standard video call into an intelligent, accessible, and globally inclusive meeting experience. By leveraging Plug-N-Meet's provider-agnostic AI layer, you can easily add a powerful ",(0,s.jsx)(n.strong,{children:"meeting assistant AI"})," that gives you a significant edge, all while maintaining full control over your self-hosted platform."]}),"\n",(0,s.jsxs)(n.p,{children:["The real power of this platform is that your data isn't trapped. After the meeting ends, you can use the ",(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/docs/api/artifact/fetch",children:"Artifacts API"})})," to programmatically retrieve the summary and transcription, allowing you to build powerful integrations with your new ",(0,s.jsx)(n.strong,{children:"AI meeting notes"}),"."]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},7365:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>a});var t=i(7140);const s={},r=t.createContext(s);function o(e){const n=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),t.createElement(r.Provider,{value:n},e.children)}},3502:e=>{e.exports=JSON.parse('{"permalink":"/blog/how-to-add-ai-meeting-assistant-features","editUrl":"https://github.com/mynaparrot/plugNmeet-docs/edit/main/blog/2026-01-03-how-to-add-ai-features.md","source":"@site/blog/2026-01-03-how-to-add-ai-features.md","title":"How to Add an AI Meeting Assistant to Your Video App in 15 Minutes","description":"In today\'s competitive landscape, a basic video call is no longer enough. Users expect intelligent, accessible, and productive experiences. What if you could offer an AI meeting assistant that provides live translation and automatically generates AI meeting notes after every session?","date":"2026-01-03T00:00:00.000Z","tags":[{"inline":true,"label":"tutorial","permalink":"/blog/tags/tutorial"},{"inline":true,"label":"how-to","permalink":"/blog/tags/how-to"},{"inline":true,"label":"ai-meeting-assistant","permalink":"/blog/tags/ai-meeting-assistant"},{"inline":true,"label":"ai-meeting-notes","permalink":"/blog/tags/ai-meeting-notes"},{"inline":true,"label":"meeting-summary-ai","permalink":"/blog/tags/meeting-summary-ai"},{"inline":true,"label":"ai-meeting-summarizer","permalink":"/blog/tags/ai-meeting-summarizer"},{"inline":true,"label":"meeting-assistant-ai","permalink":"/blog/tags/meeting-assistant-ai"},{"inline":true,"label":"developer","permalink":"/blog/tags/developer"}],"readingTime":4.04,"hasTruncateMarker":true,"authors":[{"name":"Jibon L. Costa","title":"Founding developer","url":"https://github.com/jibon57","imageURL":"https://github.com/jibon57.png","key":"jibon","page":null}],"frontMatter":{"title":"How to Add an AI Meeting Assistant to Your Video App in 15 Minutes","slug":"how-to-add-ai-meeting-assistant-features","authors":["jibon"],"tags":["tutorial","how-to","ai-meeting-assistant","ai-meeting-notes","meeting-summary-ai","ai-meeting-summarizer","meeting-assistant-ai","developer"]},"unlisted":false,"nextItem":{"title":"Stream Like a Pro: How to Bring OBS into Your plugNmeet Room","permalink":"/blog/obs-rtmp-whip-ingress"}}')}}]);